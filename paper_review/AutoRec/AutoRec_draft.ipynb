{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoRec_draft.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 220309 ~ 220310"
      ],
      "metadata": {
        "id": "i72QgqxSkRXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loss 마스킹을 하긴 했는데 loss 계산을 전부 포함시켜서 해버림. -> masking한 것들 제외하고 연산할 것."
      ],
      "metadata": {
        "id": "wXovF0Nun4pY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Purpose\n",
        "The purpose of this notebook is to review [AutoRec: Autoencoders Meet Collaborative Filtering](https://users.cecs.anu.edu.au/~akmenon/papers/autorec/autorec-paper.pdf)."
      ],
      "metadata": {
        "id": "MFvz81u8Lh-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "- Collaborative filtering models make personalised recommendations by using information about users' preferences for items.\n",
        "\n",
        "- The paper propsed AutoRec, a novel CF based on autoencoder.\n",
        "\n",
        "- The authors said that the proposed model has representational and computational advantages over other approaches."
      ],
      "metadata": {
        "id": "V3KMJdVfMEmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The AutoRec Model\n",
        "\n",
        "- The basic setup of rating based collaborative filtering\n",
        "  - $m$ : The number of users.\n",
        "  - $n$ : The number of items.\n",
        "  - $R \\in \\mathbb{R}^{m \\times n}$ : A observerd user-item rating matrix which has many missing values.\n",
        "  - $u \\in U = {1,...,m}$ : Each user\n",
        "    - a partially observed vector \n",
        "    $r^{(u)} = (R_{u1},...,R_{un}) \\in \\mathbb{R}^n$\n",
        "  - $i \\in I = {1,...,n}$\n",
        "    - a partially observed vector \n",
        "    $r^{(i)}=(R_{1i},...,R_{mi}) \\in \\mathbb{R}^m$\n",
        "\n",
        "## Purpose\n",
        "The aim is to design an autoencoder which take each partially observed $r^{(i)} (r^{(u)})$ as input, project the input into a low latent space, and reconstruct ratings in the output space.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "96yMayM1Ny2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The autoencoder optimizes \n",
        "\n",
        "$$\n",
        "min_{\\theta} \\sum_{r \\in S}||r-h(r;\\theta)||_2^2\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\n",
        "h(r;\\theta) = f(W \\cdot g(Vr+\\mu)+b)\n",
        "$$\n",
        "\n",
        "$\\theta = \\{W,V,\\mu,b\\}$\n",
        "- $W \\in \\mathbb{R}^{d\\times k} $ : Encoder weights \n",
        "- $V \\in \\mathbb{R}^{k\\times d} $ : Decoder weights\n",
        "- $\\mu \\in \\mathbb{R}^{k}$ : Encoder bias\n",
        "- $b \\in \\mathbb{R}^{d}$ : Decoder bias"
      ],
      "metadata": {
        "id": "ZH8mRrIPSDTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The autoencoder has a single and k dimesional hidden layer."
      ],
      "metadata": {
        "id": "31-z4IBhUA1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Two important details in the model\n",
        "\n",
        "1. When updating the model, only observed ratings are considered.\n",
        "\n",
        "2. To prevent overfitting on the observed ratings, $l2$ regularization loss is applied to $W$ and $V$."
      ],
      "metadata": {
        "id": "4qO6aYKSVA4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "min_{\\theta} \\sum_{i=1}^{n}||r^{(i)} - h(r^{(i)};\\theta)||_O^2 + \\frac{\\lambda}{2}\\cdot(||W||_F^2+||V||_F^2)\n",
        "$$\n",
        "\n",
        "where $||\\cdot||_O^2$ means only observed ratings are considered to update the model."
      ],
      "metadata": {
        "id": "TtdI3yYtWZj7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\hat R_{ui} = h(r^{(i)};\\hat\\theta)_u\n",
        "$$"
      ],
      "metadata": {
        "id": "CDNgOqgqYdnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "QndLfthMZBUw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movielens_data_file_url = (\n",
        "    \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        ")\n",
        "movielens_zipped_file = keras.utils.get_file(\n",
        "    \"ml-latest-small.zip\", movielens_data_file_url, extract=False\n",
        ")\n",
        "keras_datasets_path = Path(movielens_zipped_file).parents[0]\n",
        "movielens_dir = keras_datasets_path / \"ml-latest-small\"\n",
        "\n",
        "# Only extract the data the first time the script is run.\n",
        "if not movielens_dir.exists():\n",
        "    with ZipFile(movielens_zipped_file, \"r\") as Zip:\n",
        "        # Extract files\n",
        "        print(\"Extracting all the files now...\")\n",
        "        Zip.extractall(path=keras_datasets_path)\n",
        "        print(\"Done!\")\n",
        "\n",
        "ratings_file = movielens_dir / \"ratings.csv\"\n",
        "df = pd.read_csv(ratings_file)"
      ],
      "metadata": {
        "id": "uCQBxLCQZLUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd419af5-7d69-4550-db54-2824af6b16c6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting all the files now...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rating_matrix=pd.pivot(df,\"userId\",\"movieId\",\"rating\")"
      ],
      "metadata": {
        "id": "bCkf42t3aVBX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_matrix=rating_matrix.fillna(0)"
      ],
      "metadata": {
        "id": "1bELivPdGGEV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_matrix=rating_matrix.T"
      ],
      "metadata": {
        "id": "9ORt8svFazCR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "마스킹 구현할 것.\n",
        "아주 정확히 따질 거면 중간에 reg loss 계산하는 것도 다시 해야함."
      ],
      "metadata": {
        "id": "j26vDnKnjSJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://keras.io/guides/training_with_built_in_methods/\n",
        "\n",
        "\n",
        "\n",
        "https://keras.io/guides/customizing_what_happens_in_fit/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[이 사람은 loss를 custom해서 구했음.](https://github.com/supkoon/AutoRec-tf/blob/master/AutoRec.py)"
      ],
      "metadata": {
        "id": "fIAP1ySWn6GR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 아래가 내가 최초로 작성한 것. 잘못된 점을 찾아 고침"
      ],
      "metadata": {
        "id": "ogFufHokIAo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoRec(keras.layers.Layer):\n",
        "  def __init__(self, num_col=32, hidden_node=32,rate=10):\n",
        "    super(AutoRec, self).__init__()\n",
        "    self.num_col = num_col\n",
        "    self.hidden_node = hidden_node\n",
        "    #self.encoder_weight = tf.Variable((num_col,hidden_node),trainable = True)\n",
        "    #self.decoder_weight = tf.Variable((hidden_node,num_col),trainable = True)\n",
        "    #self.encoder_bias = tf.Variable((hidden_node,),trainable = True)\n",
        "    #self.decoder_bias =tf.Variable((num_col,),trainable = True)\n",
        "    self.encoder_weight = self.add_weight(\n",
        "            shape=(num_col, hidden_node), initializer=\"random_normal\", trainable=True\n",
        "        )\n",
        "    self.decoder_weight = self.add_weight(\n",
        "            shape=(hidden_node, num_col), initializer=\"random_normal\", trainable=True\n",
        "        )\n",
        "    self.encoder_bias = self.add_weight(\n",
        "            shape=(hidden_node,), initializer=\"zero\", trainable=True\n",
        "        )\n",
        "    self.decoder_bias =self.add_weight(\n",
        "            shape=(num_col,), initializer=\"zero\", trainable=True\n",
        "        )\n",
        "    self.rate = rate\n",
        "    self.encoder_regularization = keras.regularizers.l2(rate*0.5)\n",
        "    self.decoder_regularization = keras.regularizers.l2(rate*0.5)\n",
        "    \n",
        "  def call(self,input):\n",
        "    x=tf.matmul(input,self.encoder_weight) + self.encoder_bias\n",
        "    out=tf.matmul(x,self.decoder_weight) + self.decoder_bias\n",
        "\n",
        "    self.add_loss(self.encoder_regularization(self.encoder_weight))\n",
        "    self.add_loss(self.encoder_regularization(self.decoder_weight))\n",
        "\n",
        "    #out=keras.activations.sigmoid(x)\n",
        "    return out\n",
        "\n"
      ],
      "metadata": {
        "id": "dA54YHsgDEcf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 자꾸  Missing required positional argument가 발생해서 instantiation을 못하고 있었는데 tf.Variable을 잘못사용하고 있었음.\n",
        "\n",
        "### 2. 생성자 overriding할때 super선언.\n",
        "```\n",
        "super(AutoRec,self).__init__()\n",
        "```\n",
        "\n",
        "\n",
        "### [이 부분 initial_value 지정에서 틀렸음. self.add_weight으로 고쳐 쓰는 것이 quicker shortcut이라고 함.](https://keras.io/guides/making_new_layers_and_models_via_subclassing/#the-layer-class-the-combination-of-state-weights-and-some-computation)\n",
        "#### 아마도 initializer를 외부에서 설정하여 사용하지 않아도 된다는 점 때문일듯.\n",
        "```\n",
        "    self.encoder_weight = tf.Variable((num_col,hidden_node),trainable = True)\n",
        "    self.decoder_weight = tf.Variable((hidden_node,num_col),trainable = True)\n",
        "->\n",
        "w_init은 초기화할 방법에 대해 미리 선언한 뒤에 아래와 같은 방식을 사용할 수 있음.\n",
        "\n",
        "    self.encoder_weight = tf.Variable(\n",
        "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
        "            trainable=True,\n",
        "        )\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "self.encoder_weight = self.add_weight(\n",
        "            shape=(num_col, hidden_node), initializer=\"random_normal\", trainable=True\n",
        "        )\n",
        "self.decoder_weight = self.add_weight(\n",
        "            shape=(hidden_node, num_col), initializer=\"random_normal\", trainable=True\n",
        "        )\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "### 3. Activation function 도 tf.Variable을 사용했었는데, add_weight으로 대체함.\n",
        "\n",
        "\n",
        "### 4. Regularization term 추가해서 scale도 조절해야함.\n",
        "\n"
      ],
      "metadata": {
        "id": "W9XytebmIDO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 앞에서 만든 layer를 포함하여 keras.Model을 subclassing 함."
      ],
      "metadata": {
        "id": "yE_ckrP2QG50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 일단 막 짜는데 이상한 느낌들었던 부분에서 멈췄음. \n",
        "\n",
        "#### tape이 어떻게 loss를 토대로 계산했는지 명확히 기억이 안 남\n",
        "#### train step이 뭘 반환 했는지 기억이 안 남."
      ],
      "metadata": {
        "id": "78gNP0pBWdWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래서 아래 예제를 가져와봄\n",
        "\n",
        "```\n",
        "loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "```\n",
        "\n",
        "이렇게 계산했었구나\n",
        "\n",
        "train step에서 tape안에서 관측되는 것은 self (아마 다른 방식도 가능하겠지만)\n",
        "```\n",
        "y_pred=self(x,training=True)\n",
        "```\n",
        "\n",
        "layer subclassing 하는 것처럼 __init__ 과 call을 통해서 연산에 대한 디테일한 설정을 한 후에 train_step\n",
        "```\n",
        "class model(keras.Model):\n",
        "  def __init__(self,num_col,hidden,rate):\n",
        "    self.autoencoder = AutoRec(num_col,hidden,rate)\n",
        "\n",
        "  def call(self,input):\n",
        "    return self.autoencoder(input)\n",
        "\n",
        "  def train_step(self,data):\n",
        "    x,y = data\n",
        "    mask = y !=0\n",
        "    with tf.gradientTape as tape:\n",
        "      y_pred=self(x,training=True)\n",
        "      y_pred=tf.multiply(y_pred,mask)\n",
        "      loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "\n",
        "    trainable_vars = self.trainable_variables\n",
        "    gradients = tape.gradient(loss, trainable_vars)\n",
        "    self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "    \n",
        "    self.compiled_metrics.update_state(y, y_pred)\n",
        "    \n",
        "    return {m.name: m.result() for m in self.metrics}\n",
        "```"
      ],
      "metadata": {
        "id": "GzbSxipqW4Es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class model(keras.Model):\n",
        "  '''에러 나서 이 방법 안 쓰기로 함\n",
        "  공식문서 찾아봐도 이거랑 아래 조합해서 쓰는 예제가 없네..\n",
        "  def __init__(self,num_col,hidden,rate):\n",
        "    super(model,self).__init__()\n",
        "    self.autoencoder = AutoRec(num_col,hidden,rate)\n",
        "\n",
        "  def call(self,input):\n",
        "    return self.autoencoder(input)\n",
        "'''\n",
        "  def train_step(self,data):\n",
        "    x,y = data\n",
        "    \n",
        "    mask = y !=0\n",
        "    \n",
        "    mask=tf.cast(mask, tf.float32)\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred=self(x,training=True)\n",
        "     # print(\"###########y_pred############333\",y_pred)\n",
        "      #print(mask)\n",
        "      \n",
        "      y_pred=tf.multiply(y_pred,mask)\n",
        "      y=tf.cast(y, tf.float32)\n",
        "      #print(y_pred-y)\n",
        "      #print(tf.reduce_sum(tf.math.square(y_pred-y),axis=1))\n",
        "      #print(tf.reduce_sum(mask,axis =1))\n",
        "      #print(tf.reduce_sum(tf.math.square(y_pred-y),axis=1)/tf.reduce_sum(mask,axis =1))\n",
        "      \n",
        "      # 아예 0인건 계산에서 빼버려야하는 거 아닌가? 맞음.\n",
        "      #print(tf.reduce_sum(mask,axis =1))\n",
        "      loss=tf.reduce_mean(tf.reduce_sum(tf.math.square(y_pred-y),axis=1)/tf.reduce_sum(mask,axis =1)) # loss custom 해봄.\n",
        "      # 문제는 이렇게 tf.GradientTape 안에서 compiled_loss를 사용하지 않고 이렇게 써도 되는지 모르겠음.\n",
        "\n",
        "      #print(tf.reduce_mean(tmp))\n",
        "      #loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "    \n",
        "    #print(loss)\n",
        "    trainable_vars = self.trainable_variables\n",
        "    gradients = tape.gradient(loss, trainable_vars)\n",
        "    #print(\"###########gradients############\",zip(gradients, trainable_vars))\n",
        "    self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "    \n",
        "    self.compiled_metrics.update_state(y, y_pred)\n",
        "    print(\"\\n========================================================\")\n",
        "    print(loss)\n",
        "    print(\"========================================================\\n\")\n",
        "    return {m.name: m.result() for m in self.metrics}"
      ],
      "metadata": {
        "id": "52CU2SYiI313"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input=layers.Input(shape = (rating_matrix.shape[1]))\n",
        "output= AutoRec(rating_matrix.shape[1],500,10)(input)\n",
        "m = model(input,output)\n",
        "m.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"],run_eagerly=True)"
      ],
      "metadata": {
        "id": "6eF_9Py9WdAf"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m.fit(rating_matrix, rating_matrix, epochs=50)"
      ],
      "metadata": {
        "id": "0gpY9S17ZokY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "pGtaG31ZlBMa",
        "outputId": "96868ca8-d94f-4899-ec16-63426e2e1584"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-45d2d556-1844-48b7-81c1-907ba31e8fdc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>userId</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>601</th>\n",
              "      <th>602</th>\n",
              "      <th>603</th>\n",
              "      <th>604</th>\n",
              "      <th>605</th>\n",
              "      <th>606</th>\n",
              "      <th>607</th>\n",
              "      <th>608</th>\n",
              "      <th>609</th>\n",
              "      <th>610</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>movieId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193581</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193583</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193585</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193587</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193609</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9724 rows × 610 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45d2d556-1844-48b7-81c1-907ba31e8fdc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45d2d556-1844-48b7-81c1-907ba31e8fdc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45d2d556-1844-48b7-81c1-907ba31e8fdc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "userId   1    2    3    4    5    6    7    8    9    10   ...  601  602  603  \\\n",
              "movieId                                                    ...                  \n",
              "1        4.0  0.0  0.0  0.0  4.0  0.0  4.5  0.0  0.0  0.0  ...  4.0  0.0  4.0   \n",
              "2        0.0  0.0  0.0  0.0  0.0  4.0  0.0  4.0  0.0  0.0  ...  0.0  4.0  0.0   \n",
              "3        4.0  0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "4        0.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "5        0.0  0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "193581   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "193583   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "193585   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "193587   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "193609   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "\n",
              "userId   604  605  606  607  608  609  610  \n",
              "movieId                                     \n",
              "1        3.0  4.0  2.5  4.0  2.5  3.0  5.0  \n",
              "2        5.0  3.5  0.0  0.0  2.0  0.0  0.0  \n",
              "3        0.0  0.0  0.0  0.0  2.0  0.0  0.0  \n",
              "4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "5        3.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "...      ...  ...  ...  ...  ...  ...  ...  \n",
              "193581   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "193583   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "193585   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "193587   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "193609   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "\n",
              "[9724 rows x 610 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(m.predict(rating_matrix))"
      ],
      "metadata": {
        "id": "TQs8GGwglOs_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "01761876-bc63-455f-8abe-767fc275da98"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-358921b2-65c7-443f-a515-d75bbab92a85\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>600</th>\n",
              "      <th>601</th>\n",
              "      <th>602</th>\n",
              "      <th>603</th>\n",
              "      <th>604</th>\n",
              "      <th>605</th>\n",
              "      <th>606</th>\n",
              "      <th>607</th>\n",
              "      <th>608</th>\n",
              "      <th>609</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.844972</td>\n",
              "      <td>4.594985</td>\n",
              "      <td>1.525867</td>\n",
              "      <td>4.549614</td>\n",
              "      <td>3.731117</td>\n",
              "      <td>2.047221</td>\n",
              "      <td>4.924703</td>\n",
              "      <td>3.741935</td>\n",
              "      <td>3.002219</td>\n",
              "      <td>2.667315</td>\n",
              "      <td>...</td>\n",
              "      <td>3.210745</td>\n",
              "      <td>4.961127</td>\n",
              "      <td>3.029745</td>\n",
              "      <td>3.997644</td>\n",
              "      <td>3.240583</td>\n",
              "      <td>1.419571</td>\n",
              "      <td>3.897580</td>\n",
              "      <td>2.589986</td>\n",
              "      <td>2.760815</td>\n",
              "      <td>3.974326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.810694</td>\n",
              "      <td>3.138782</td>\n",
              "      <td>1.064634</td>\n",
              "      <td>3.561512</td>\n",
              "      <td>2.369931</td>\n",
              "      <td>4.023575</td>\n",
              "      <td>2.720996</td>\n",
              "      <td>2.523205</td>\n",
              "      <td>3.181528</td>\n",
              "      <td>0.749501</td>\n",
              "      <td>...</td>\n",
              "      <td>3.326495</td>\n",
              "      <td>3.978842</td>\n",
              "      <td>1.504849</td>\n",
              "      <td>4.444207</td>\n",
              "      <td>3.637628</td>\n",
              "      <td>0.207120</td>\n",
              "      <td>3.223299</td>\n",
              "      <td>2.144930</td>\n",
              "      <td>1.701288</td>\n",
              "      <td>1.247058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.213321</td>\n",
              "      <td>2.215713</td>\n",
              "      <td>0.342085</td>\n",
              "      <td>-0.013551</td>\n",
              "      <td>1.875339</td>\n",
              "      <td>5.563408</td>\n",
              "      <td>1.906689</td>\n",
              "      <td>2.049202</td>\n",
              "      <td>1.330980</td>\n",
              "      <td>0.191644</td>\n",
              "      <td>...</td>\n",
              "      <td>3.185682</td>\n",
              "      <td>2.378269</td>\n",
              "      <td>-0.348938</td>\n",
              "      <td>3.034824</td>\n",
              "      <td>1.488632</td>\n",
              "      <td>0.675076</td>\n",
              "      <td>3.161333</td>\n",
              "      <td>1.930621</td>\n",
              "      <td>0.959571</td>\n",
              "      <td>1.528508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.248401</td>\n",
              "      <td>0.823507</td>\n",
              "      <td>0.512388</td>\n",
              "      <td>0.456561</td>\n",
              "      <td>0.989806</td>\n",
              "      <td>2.818503</td>\n",
              "      <td>0.802297</td>\n",
              "      <td>0.875989</td>\n",
              "      <td>0.315764</td>\n",
              "      <td>0.100902</td>\n",
              "      <td>...</td>\n",
              "      <td>1.190710</td>\n",
              "      <td>1.024129</td>\n",
              "      <td>-0.337405</td>\n",
              "      <td>0.945827</td>\n",
              "      <td>-0.090366</td>\n",
              "      <td>-0.309352</td>\n",
              "      <td>0.791049</td>\n",
              "      <td>0.137053</td>\n",
              "      <td>0.877094</td>\n",
              "      <td>-0.430943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.773895</td>\n",
              "      <td>2.392127</td>\n",
              "      <td>1.185333</td>\n",
              "      <td>1.647378</td>\n",
              "      <td>2.181593</td>\n",
              "      <td>5.011390</td>\n",
              "      <td>1.129585</td>\n",
              "      <td>2.101210</td>\n",
              "      <td>2.645389</td>\n",
              "      <td>0.136154</td>\n",
              "      <td>...</td>\n",
              "      <td>2.968727</td>\n",
              "      <td>2.129581</td>\n",
              "      <td>-0.645748</td>\n",
              "      <td>3.138445</td>\n",
              "      <td>0.135776</td>\n",
              "      <td>1.570883</td>\n",
              "      <td>3.757101</td>\n",
              "      <td>0.588425</td>\n",
              "      <td>1.877959</td>\n",
              "      <td>2.476816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9719</th>\n",
              "      <td>0.963879</td>\n",
              "      <td>1.190617</td>\n",
              "      <td>0.690791</td>\n",
              "      <td>0.624387</td>\n",
              "      <td>0.865361</td>\n",
              "      <td>0.721183</td>\n",
              "      <td>0.464213</td>\n",
              "      <td>0.681566</td>\n",
              "      <td>0.328523</td>\n",
              "      <td>0.159483</td>\n",
              "      <td>...</td>\n",
              "      <td>1.178959</td>\n",
              "      <td>0.750882</td>\n",
              "      <td>0.419192</td>\n",
              "      <td>0.759898</td>\n",
              "      <td>0.146504</td>\n",
              "      <td>0.337749</td>\n",
              "      <td>0.734244</td>\n",
              "      <td>0.100395</td>\n",
              "      <td>0.647216</td>\n",
              "      <td>0.044765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9720</th>\n",
              "      <td>0.961995</td>\n",
              "      <td>1.150426</td>\n",
              "      <td>0.658937</td>\n",
              "      <td>0.592730</td>\n",
              "      <td>0.846558</td>\n",
              "      <td>0.698676</td>\n",
              "      <td>0.463599</td>\n",
              "      <td>0.677393</td>\n",
              "      <td>0.325936</td>\n",
              "      <td>0.165043</td>\n",
              "      <td>...</td>\n",
              "      <td>1.153136</td>\n",
              "      <td>0.770852</td>\n",
              "      <td>0.371332</td>\n",
              "      <td>0.752576</td>\n",
              "      <td>0.150548</td>\n",
              "      <td>0.313324</td>\n",
              "      <td>0.758904</td>\n",
              "      <td>0.106619</td>\n",
              "      <td>0.671012</td>\n",
              "      <td>0.045473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9721</th>\n",
              "      <td>0.961995</td>\n",
              "      <td>1.150426</td>\n",
              "      <td>0.658937</td>\n",
              "      <td>0.592730</td>\n",
              "      <td>0.846558</td>\n",
              "      <td>0.698676</td>\n",
              "      <td>0.463599</td>\n",
              "      <td>0.677393</td>\n",
              "      <td>0.325936</td>\n",
              "      <td>0.165043</td>\n",
              "      <td>...</td>\n",
              "      <td>1.153136</td>\n",
              "      <td>0.770852</td>\n",
              "      <td>0.371332</td>\n",
              "      <td>0.752576</td>\n",
              "      <td>0.150548</td>\n",
              "      <td>0.313324</td>\n",
              "      <td>0.758904</td>\n",
              "      <td>0.106619</td>\n",
              "      <td>0.671012</td>\n",
              "      <td>0.045473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9722</th>\n",
              "      <td>0.961995</td>\n",
              "      <td>1.150426</td>\n",
              "      <td>0.658937</td>\n",
              "      <td>0.592730</td>\n",
              "      <td>0.846558</td>\n",
              "      <td>0.698676</td>\n",
              "      <td>0.463599</td>\n",
              "      <td>0.677393</td>\n",
              "      <td>0.325936</td>\n",
              "      <td>0.165043</td>\n",
              "      <td>...</td>\n",
              "      <td>1.153136</td>\n",
              "      <td>0.770852</td>\n",
              "      <td>0.371332</td>\n",
              "      <td>0.752576</td>\n",
              "      <td>0.150548</td>\n",
              "      <td>0.313324</td>\n",
              "      <td>0.758904</td>\n",
              "      <td>0.106619</td>\n",
              "      <td>0.671012</td>\n",
              "      <td>0.045473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9723</th>\n",
              "      <td>1.208365</td>\n",
              "      <td>0.816681</td>\n",
              "      <td>0.351751</td>\n",
              "      <td>0.363547</td>\n",
              "      <td>0.855505</td>\n",
              "      <td>0.351728</td>\n",
              "      <td>0.285040</td>\n",
              "      <td>0.683316</td>\n",
              "      <td>0.221654</td>\n",
              "      <td>0.156149</td>\n",
              "      <td>...</td>\n",
              "      <td>1.315296</td>\n",
              "      <td>0.995985</td>\n",
              "      <td>0.201540</td>\n",
              "      <td>0.746805</td>\n",
              "      <td>0.419725</td>\n",
              "      <td>0.151124</td>\n",
              "      <td>0.746384</td>\n",
              "      <td>0.155479</td>\n",
              "      <td>0.836909</td>\n",
              "      <td>0.023088</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9724 rows × 610 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-358921b2-65c7-443f-a515-d75bbab92a85')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-358921b2-65c7-443f-a515-d75bbab92a85 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-358921b2-65c7-443f-a515-d75bbab92a85');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           0         1         2         3         4         5         6    \\\n",
              "0     5.844972  4.594985  1.525867  4.549614  3.731117  2.047221  4.924703   \n",
              "1     2.810694  3.138782  1.064634  3.561512  2.369931  4.023575  2.720996   \n",
              "2     4.213321  2.215713  0.342085 -0.013551  1.875339  5.563408  1.906689   \n",
              "3     1.248401  0.823507  0.512388  0.456561  0.989806  2.818503  0.802297   \n",
              "4     1.773895  2.392127  1.185333  1.647378  2.181593  5.011390  1.129585   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "9719  0.963879  1.190617  0.690791  0.624387  0.865361  0.721183  0.464213   \n",
              "9720  0.961995  1.150426  0.658937  0.592730  0.846558  0.698676  0.463599   \n",
              "9721  0.961995  1.150426  0.658937  0.592730  0.846558  0.698676  0.463599   \n",
              "9722  0.961995  1.150426  0.658937  0.592730  0.846558  0.698676  0.463599   \n",
              "9723  1.208365  0.816681  0.351751  0.363547  0.855505  0.351728  0.285040   \n",
              "\n",
              "           7         8         9    ...       600       601       602  \\\n",
              "0     3.741935  3.002219  2.667315  ...  3.210745  4.961127  3.029745   \n",
              "1     2.523205  3.181528  0.749501  ...  3.326495  3.978842  1.504849   \n",
              "2     2.049202  1.330980  0.191644  ...  3.185682  2.378269 -0.348938   \n",
              "3     0.875989  0.315764  0.100902  ...  1.190710  1.024129 -0.337405   \n",
              "4     2.101210  2.645389  0.136154  ...  2.968727  2.129581 -0.645748   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "9719  0.681566  0.328523  0.159483  ...  1.178959  0.750882  0.419192   \n",
              "9720  0.677393  0.325936  0.165043  ...  1.153136  0.770852  0.371332   \n",
              "9721  0.677393  0.325936  0.165043  ...  1.153136  0.770852  0.371332   \n",
              "9722  0.677393  0.325936  0.165043  ...  1.153136  0.770852  0.371332   \n",
              "9723  0.683316  0.221654  0.156149  ...  1.315296  0.995985  0.201540   \n",
              "\n",
              "           603       604       605       606       607       608       609  \n",
              "0     3.997644  3.240583  1.419571  3.897580  2.589986  2.760815  3.974326  \n",
              "1     4.444207  3.637628  0.207120  3.223299  2.144930  1.701288  1.247058  \n",
              "2     3.034824  1.488632  0.675076  3.161333  1.930621  0.959571  1.528508  \n",
              "3     0.945827 -0.090366 -0.309352  0.791049  0.137053  0.877094 -0.430943  \n",
              "4     3.138445  0.135776  1.570883  3.757101  0.588425  1.877959  2.476816  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "9719  0.759898  0.146504  0.337749  0.734244  0.100395  0.647216  0.044765  \n",
              "9720  0.752576  0.150548  0.313324  0.758904  0.106619  0.671012  0.045473  \n",
              "9721  0.752576  0.150548  0.313324  0.758904  0.106619  0.671012  0.045473  \n",
              "9722  0.752576  0.150548  0.313324  0.758904  0.106619  0.671012  0.045473  \n",
              "9723  0.746805  0.419725  0.151124  0.746384  0.155479  0.836909  0.023088  \n",
              "\n",
              "[9724 rows x 610 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.predict(rating_matrix.iloc[0:1,:])"
      ],
      "metadata": {
        "id": "FkIwFw5iiJ_2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
